# Техническая документация: `react_driver.py` — Ядро когнитивного обогащения

## 1. Обзор

`react_driver.py` — это **исследовательское ядро (R&D Core)** и центральный оркестратор "Magic Proxy". Этот модуль реализует сложный асинхронный фреймворк, основанный на паттерне **ReAct (Reasoning and Acting)**.

Однако его цель — не создание обычного чат-бота, а **когнитивная аугментация (Cognitive Augmentation)** запросов в реальном времени. Он действует как "умный" препроцессор, который симулирует или усилирует когнитивные способности целевой LLM, генерируя глубокий, структурированный контекст рассуждений *перед* тем, как модель даст финальный ответ.

## 2. Концепция: Рассуждение как Услуга (Reasoning-as-a-Service)

Стандартный прокси-сервер просто перенаправляет запросы. "Magic Proxy" с `react_driver` трансформирует их. Модуль предлагает "Рассуждение как Услугу", решая фундаментальные проблемы современных AI-моделей:

*   **Наделение мышлением**: Позволяет "слабым" и недорогим моделям, неспособным к самостоятельному сложному рассуждению, выполнять многошаговые задачи и использовать внешние инструменты.
*   **Усиление способностей**: Повышает качество, глубину и надежность ответов даже самых мощных моделей, заставляя их следовать предсказуемому и верифицируемому процессу рассуждения.
*   **"Виртуальное дообучение" через промптинг**: Эмулирует поведение тонко настроенной (fine-tuned) модели для специфических задач, но делает это "на лету" с помощью продвинутого, итеративного промпт-инжиниринга. Это значительно быстрее и дешевле, чем реальное дообучение.

В сущности, `react_driver` превращает прокси из пассивного маршрутизатора в **активный интеллектуальный шлюз**, добавляющий ценность каждому запросу.

## 3. Архитектура и ключевые паттерны

Для реализации этой сложной задачи модуль использует отказоустойчивую, распределенную архитектуру.

*   **Декаплированный исполнительный фреймворк (CQRS + Kafka)**: Запрос на "обогащение" не выполняется немедленно. Он отправляется как команда в **Kafka**, а отдельный пул фоновых воркеров асинхронно выполняет ресурсоемкий процесс рассуждения. Это обеспечивает высокую производительность и масштабируемость.
*   **Прозрачная обратная связь (Redis Pub/Sub + SSE)**: Несмотря на асинхронность, клиент может наблюдать за всем процессом когнитивного обогащения в реальном времени. `react_driver` использует **Redis Pub/Sub** и **Server-Sent Events (SSE)** для трансляции потока "мыслей", вызовов инструментов и промежуточных результатов.
*   **Итеративный движок рассуждений (`AgentStepProcessor`)**: Это "мозг" процесса. Его цель — не просто решить задачу, а построить **"блокнот" (scratchpad)** — подробный, структурированный след рассуждений (`Thought -> Action -> Observation`). Этот scratchpad является главным артефактом, который затем используется для генерации финального, обогащенного ответа.
*   **Отказоустойчивый вызов LLM (`_execute_react_step_with_fallback`)**: Гарантирует, что долгий и сложный процесс рассуждения не прервется из-за сбоя одного API-ключа или даже целого провайдера, обеспечивая надежность всего R&D-процесса.

## 4. Платформа для создания цепочек рассуждений (Reasoning Chains)

`react_driver` спроектирован не для одного ReAct-паттерна, а как гибкая **платформа для создания, тестирования и развертывания кастомных цепочек рассуждений**. Вместо того чтобы заставлять пользователей изучать сложные фреймворки, "Magic Proxy" предлагает предельно простой, основанный на файлах, способ определения новых когнитивных архитектур.

### 4.1. Примеры возможных паттернов

*   **Стандартный ReAct (уже реализован)**: Классический цикл `Thought -> Action -> Observation` для использования инструментов.
*   **Паттерн "Deep Research"**: Многошаговый паттерн, который заставляет модель сначала составить план (`Plan`), затем итеративно искать информацию (`Search`), синтезировать найденное (`Synthesize`) и только потом давать финальный ответ (`Final Answer`).
*   **Паттерн "Экспертной Делегации"**: Паттерн, где основная модель-оркестратор анализирует задачу и, вместо прямого решения, вызывает другие, более специализированные модели или агентов через `mcp_server.py` как инструменты.

### 4.2. Руководство: Создание нового паттерна за 3 шага

Ключевое преимущество системы — **автоматическое обнаружение**. Системе не нужно "сообщать" о новых паттернах. Достаточно создать файл в нужной папке.

**Шаг 1: Создайте файл в `react_patterns/`**
Имя файла должно заканчиваться на `_react.py`. Например, `deep_research_react.py`.
```
.
├── react_patterns/
│   ├── basic_react.py
│   └── deep_research_react.py  # <-- Ваш новый файл
└── react_driver.py
```
Система автоматически найдет этот файл и зарегистрирует паттерн `deep_research_react`.

**Шаг 2: Определите структуру промпта**
Внутри файла создайте функцию `get_prompt_structure()`, которая возвращает список словарей, описывающих шаги рассуждения.
```python
# react_patterns/deep_research_react.py
def get_prompt_structure():
    return [
        {"tag": "PLAN", "content": "You must create a step-by-step plan..."},
        {"tag": "EXECUTION", "content": "Execute the plan..."},
        {"tag": "SYNTHESIS", "content": "Synthesize the gathered information..."},
        {"tag": "FINAL_ANSWER", "content": "Provide the final answer..."}
    ]
```

**Шаг 3: Активируйте паттерн в `proxy_config.yaml`**
Привяжите новый паттерн к профилю модели, чтобы создать новый "виртуальный" AI-интеллект.
```yaml
# proxy_config.yaml
model_list:
  - model_name: "some_powerful_model"
    provider: "openai"
    model_params:
      model: "gpt-4-turbo"
      agent_settings:
        reasoning_mode: "deep_research_react" # <--- Указываем наш новый паттерн

router_settings:
  model_group_alias:
    "gpt4-deep-research": # <--- Создаем псевдоним для нового интеллекта
      - "some_powerful_model"
```
**Готово!** Теперь запросы к `model: "gpt4-deep-research"` будут заставлять `gpt-4-turbo` следовать вашему новому, сложному паттерну "Deep Research".

### 4.3. Ограничения и направления развития

*   **Ограничение**: На текущий момент движок может работать нестабильно с моделями, которые уже имеют сильные встроенные ReAct-паттерны (например, Gemini Pro). Попытка наложить внешнюю цепочку рассуждений на модель, которая уже пытается рассуждать самостоятельно, может приводить к конфликтам.
*   **Рекомендация**: Наибольшую ценность `react_driver` приносит при аугментации моделей с ограниченными нативными способностями к рассуждению (например, gpt-4o-mini, модели от Mistral, Llama и др.).
*   **Будущее развитие**: Решение этого конфликта является активной областью исследований для проекта.

## 5. Жизненный цикл "обогащенного" запроса

1.  Клиент отправляет запрос на эндпоинт `/v1/react/sessions`, указывая `model_alias`, для которого в `proxy_config.yaml` включен `reasoning_mode`.
2.  `react_driver` отправляет задачу в **Kafka** и открывает **SSE-соединение** с клиентом через Redis.
3.  Фоновый воркер получает задачу и запускает `AgentStepProcessor`.
4.  Начинается итеративный **цикл построения контекста (scratchpad)**:
    a. `prompt_constructor` собирает иерархический промпт для текущего шага.
    b. `_execute_react_step_with_fallback` надежно вызывает LLM.
    c. Воркер парсит "мысль" (`Thought`) и "действие" (`Action`), транслируя их клиенту для наглядности.
    d. Если есть "действие", вызывается инструмент через `mcp_server.py`.
    e. `scratchpad` пополняется результатом (`Observation`).
    f. Цикл повторяется, пока модель не сгенерирует тег `<FINAL_ANSWER>`.
5.  Содержимое тега `<FINAL_ANSWER>`, сгенерированное на основе всего накопленного контекста, транслируется клиенту как финальный, обогащенный ответ.

## 6. Архитектурная и бизнес-ценность

*   **Когнитивная аугментация**: Позволяет получать от LLM ответы значительно более высокого качества.
*   **Экономическая эффективность**: Дает возможность использовать более дешевые модели для решения сложных задач, снижая операционные расходы.
*   **Гибкость и управляемость**: Предоставляет мощный R&D-инструмент для кастомизации поведения моделей без необходимости их дообучения.
*   **Уникальное торговое предложение (УТП)**: Ключевая особенность прокси — не просто роутинг и фолбэк, а способность интеллектуально трансформировать и обогащать AI-запросы "на лету".