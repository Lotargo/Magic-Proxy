# Техническая Документация: Модуль providers.py

## 1. Краткое Резюме

`providers.py` реализует архитектурный паттерн "Адаптер" (Adapter Pattern), выступая в роли унифицированного слоя преобразования данных для всех внешних AI-сервисов. Модуль представляет собой набор функций-"переводчиков", каждая из которых инкапсулирует специфику взаимодействия с API конкретного провайдера (Google, OpenAI, Mistral и др.). Его задача — преобразование стандартизированных внутренних моделей (например, `ChatCompletionRequest`) в форматы внешних API и обратная трансформация их ответов в единый, канонический вид.

## 2. Архитектурная Роль и Решаемая Проблема

AI-экосистема фрагментирована: каждый провайдер предлагает свой уникальный API со своей структурой данных, названиями полей и логикой. Прямая интеграция с множеством таких API в основной бизнес-логике привела бы к "загрязнению" кода, сильной связанности и сложности расширения.

`providers.py` решает эту проблему, создавая абстрактный, изолированный слой, который скрывает всю сложность и разнородность внешних API, предоставляя остальной системе простой и унифицированный интерфейс для выполнения AI-операций.

## 3. Ключевые Адаптеры и Реализация

Каждая функция `proxy_*` в этом модуле является адаптером, который выполняет три шага:
1.  **Трансформация Запроса:** Преобразует внутренний Pydantic-объект в JSON-payload, соответствующий формату целевого API.
2.  **HTTP-Взаимодействие:** Осуществляет асинхронный HTTP-вызов к эндпоинту провайдера с помощью `httpx`.
3.  **Трансформация Ответа:** Парсит ответ от провайдера и преобразует его обратно в унифицированный Pydantic-объект (например, `ChatCompletionResponse`).

### 3.1. Специализированный Адаптер: Google Gemini (proxy_google_*)

Эти адаптеры содержат сложную логику, уникальную для Google Gemini API, для обеспечения полной совместимости.
*   **Трансформация сообщений:** Gemini API требует строгого чередования ролей `user`/`model`. Адаптер автоматически объединяет последовательные сообщения от пользователя в одно, чтобы соответствовать этому требованию.
*   **Преобразование ролей:** Роль "assistant" из стандарта OpenAI преобразуется в "model". Роль "tool" преобразуется в специальную структуру с "functionResponse".
*   **Нормализация параметров:** Названия полей приводятся в соответствие (например, `top_p` -> `topP`, `max_tokens` -> `maxOutputTokens`).
*   **Обработка ответа:** Адаптер корректно обрабатывает специфические ответы Gemini, включая информацию о блокировке контента (`promptFeedback`) и преобразование кодов завершения (`finishReason`) в стандарт OpenAI (`MAX_TOKENS` -> `length`).

### 3.2. Универсальный Адаптер: OpenAI-Совместимые (proxy_openai_compat_*)

Этот адаптер является примером обобщенного решения для провайдеров, следующих стандарту OpenAI (Mistral, DeepSeek, локальные модели через Llama.cpp и др.).
*   **Гибкая передача параметров:** Вместо ручного сопоставления полей, адаптер использует `req.model_dump(exclude_none=True)`. Это позволяет автоматически передавать любые стандартные и кастомные параметры, поддерживаемые целевым API, без необходимости изменять код адаптера.
*   **Динамическая конфигурация:** URL (`api_base`) и специфические параметры (например, `safe_prompt` для Mistral) берутся из `model_config`, что делает адаптер легко настраиваемым для новых провайдеров через `proxy_config.yaml`.

### 3.3. Реализация Стриминга (*_stream)

Модуль предоставляет потоковые версии адаптеров для интерактивных сценариев.
*   **Прозрачный прокси:** В большинстве случаев (`typewriter_mode: "client"`) адаптер просто асинхронно передает "сырые" SSE-чанки от провайдера клиенту.
*   **Режим "пишущей машинки" (`typewriter_mode: "proxy"`):** В этом режиме адаптер буферизует чанки ответа и отдает их клиенту посимвольно с небольшой задержкой, имитируя эффект печати. Это более сложная логика, которая полностью инкапсулирована внутри этого слоя.

### 3.4. Поддержка Мультимодальности (proxy_google_tts)

Наличие адаптера для синтеза речи (Text-to-Speech) демонстрирует расширяемость паттерна.
*   **Механизм:** Адаптер `proxy_google_tts` принимает стандартизированный `SpeechCreationRequest`, формирует сложный JSON-payload для Google Cloud TTS API, выполняет запрос и декодирует ответ из Base64, после чего отдает клиенту готовый аудиопоток (`StreamingResponse`) с правильным `media_type`.

## 4. Руководство по Интеграции и Расширению

Это практическое руководство показывает, как расширять возможности шлюза, добавляя поддержку новых AI-провайдеров.

### 4.1. Пример 1: Добавление OpenAI-совместимого провайдера (простой случай)

Предположим, мы хотим добавить поддержку нового провайдера "Groq", который предоставляет OpenAI-совместимый API. В этом случае изменения в код `providers.py` не требуются. Вся работа выполняется в конфигурационном файле.

**Шаг 1: Настроить модель в `proxy_config.yaml`**
Добавьте новую запись в `model_list`, указав `openai` в качестве `provider`. Это "скажет" шлюзу использовать универсальный адаптер `proxy_openai_compat_chat`.

```yaml
# proxy_config.yaml
model_list:
  # ... другие модели ...
  - model_name: "groq_llama3_70b"  # Уникальное внутреннее имя
    provider: "openai"              # <--- Указываем, что нужно использовать универсальный адаптер
    model_params:
      model: "llama3-70b-8192"      # Реальное имя модели на стороне Groq
      api_base: "https://api.groq.com/openai/v1" # <--- Указываем кастомный URL API
```

**Шаг 2: Создать псевдоним для доступа**
Сделайте новую модель доступной для клиентов, добавив ее в `model_group_alias`.

```yaml
# proxy_config.yaml
router_settings:
  model_group_alias:
    # ... другие псевдонимы ...
    "groq-llama": # Псевдоним, который будет использовать клиент
      - "groq_llama3_70b"
```

**Шаг 3: Добавить API-ключи**
Создайте новый файл `keys_pool/keys_pool_groq.env` и поместите в него API-ключи от Groq.

**Готово!** После перезапуска шлюз сможет принимать запросы к `model: "groq-llama"` и прозрачно перенаправлять их на API Groq, используя универсальный адаптер `proxy_openai_compat_chat`.

### 4.2. Пример 2: Создание адаптера для нового провайдера (сложный случай)

Предположим, появился новый провайдер "NexusAI" с полностью уникальным API, несовместимым с OpenAI.

**Шаг 1: Написать новый адаптер в `providers.py`**
Создайте новую асинхронную функцию `proxy_nexusai_chat`, следуя трехступенчатому шаблону.

```python
# В файле providers.py
# ... другие импорты ...

async def proxy_nexusai_chat(req: ChatCompletionRequest, model_config: dict, key: str, **kwargs) -> ChatCompletionResponse:
    """
    Адаптер для нового, несовместимого провайдера NexusAI.
    """
    api_url = "https://api.nexus.ai/v2/generate"
    headers = {"X-Api-Key": key}

    # 1. Трансформация запроса (Mapping)
    # Преобразуем стандартный ChatCompletionRequest в формат NexusAI
    nexus_prompt = "\n".join([f"{msg['role'].upper()}: {msg['content']}" for msg in req.messages])
    payload = {
        "prompt": nexus_prompt,
        "model_id": model_config["model_params"]["model"],
        "generation_params": {
            "creativity": req.temperature, # temperature -> creativity
            "max_new_words": req.max_tokens # max_tokens -> max_new_words
        }
    }

    # 2. HTTP-вызов
    async with httpx.AsyncClient() as client:
        response = await client.post(api_url, json=payload, headers=headers, timeout=300.0)
    response.raise_for_status()
    nexus_resp = response.json()

    # 3. Трансформация ответа (Normalization)
    # Преобразуем ответ от NexusAI обратно в стандартный ChatCompletionResponse
    final_message = ChatCompletionMessage(
        role="assistant",
        content=nexus_resp.get("generated_text", "")
    )
    final_choice = ChatCompletionChoice(
        index=0,
        message=final_message,
        finish_reason="stop" # NexusAI может не возвращать причину, ставим по умолчанию
    )
    return ChatCompletionResponse(
        id=f"chatcmpl-nexus-{uuid.uuid4().hex}",
        object="chat.completion",
        created=int(time.time()),
        model=req.model,
        choices=[final_choice],
        usage={ # NexusAI может не возвращать usage, ставим заглушки
            "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0
        }
    )
```

**Шаг 2: Зарегистрировать новый адаптер**
В файле `main.py` (или где находится функция `register_providers`) добавьте новый адаптер в "реестр".

```python
# В файле main.py (или аналогичном)
def register_providers():
    # ...
    PROVIDER_MAP_CHAT = {
        "google": proxy_google_chat,
        "openai": proxy_openai_compat_chat,
        # ...
        "nexusai": proxy_nexusai_chat # <--- Добавляем новую запись
    }
    # ...
```

**Шаг 3: Настроить и использовать новую модель**
Теперь настройте новую модель в `proxy_config.yaml`, указав `provider: "nexusai"`, и добавьте для нее ключи. После этого она станет доступна для использования через шлюз.

## 5. Архитектурная Ценность и Бизнес-Эффект

`providers.py` — это критически важный компонент, обеспечивающий гибкость и долгосрочную жизнеспособность архитектуры.
*   **Низкая Связанность:** Ядро системы не зависит от конкретных реализаций API. Вся логика, связанная с одним провайдером, находится в одном месте.
*   **Повышенная Поддерживаемость:** Если Google изменит свой API, потребуется внести изменения только в `proxy_google_*` функции в этом файле.
*   **Ускоренное Расширение:** Для добавления нового OpenAI-совместимого провайдера достаточно добавить его в `proxy_config.yaml`. Для несовместимого — реализовать новый адаптер в этом модуле.
*   **Изоляция и Тестируемость:** Каждый адаптер является чистой, изолированной функцией, которую можно легко покрыть модульными тестами.

В сущности, `providers.py` является образцовой реализацией слоя-посредника, который позволяет системе оставаться гибкой, масштабируемой и устойчивой к изменениям в постоянно развивающейся экосистеме внешних AI-сервисов.