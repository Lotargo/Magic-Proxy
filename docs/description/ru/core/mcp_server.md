# Техническая документация: `mcp_server.py` — Универсальный Сервер Инструментов

## 1. Обзор

`mcp_server.py` — это специализированный микросервис на базе FastAPI, реализующий архитектурный паттерн **"Универсальный Сервер Инструментов" (Universal Tool Server)**. Его основная задача — инкапсулировать, защищать и предоставлять стандартизированный доступ к любым исполнимым ресурсам, которые мы называем "инструментами".

Эти инструменты могут быть чем угодно:
*   Внешние API (например, веб-поиск, погодные сервисы).
*   Внутренние вычислительные функции (например, калькуляторы, обработчики данных).
*   Сложные конвейеры обработки данных (ETL, RAG).
*   Даже другие AI-агенты, выступающие в роли "экспертов".

`mcp_server` выступает как централизованный, строго типизированный и безопасный шлюз, который полностью отделяет логику выполнения инструментов от основной бизнес-логики AI-агента.

## 2. Архитектурная роль и решаемая проблема

В современных AI-системах требуется доступ к широкому спектру инструментов. Прямая интеграция этих инструментов в ядро приложения (`react_driver.py`) неизбежно привела бы к ряду проблем:

*   **Монолитность**: Добавление или обновление любого инструмента требовало бы модификации и полного переразвертывания всего приложения.
*   **Ограниченная масштабируемость**: Прямая интеграция плохо масштабируется на сложные пайплайны или асинхронные задачи.
*   **Нарушение принципа единственной ответственности (SRP)**: Ядро приложения было бы перегружено логикой взаимодействия с каждым конкретным инструментом.
*   **Риски безопасности**: API-ключи и другие учетные данные всех инструментов были бы сосредоточены в одном месте, что повышает риск их утечки в логи или в контекст LLM.

`mcp_server.py` решает эти проблемы, вынося всю логику работы с инструментами в **отдельный, легковесный и независимый сервис**. Он действует как **цифровой сейф** для всех секретов, связанных с инструментами, и предоставляет единый, унифицированный интерфейс для их вызова.

## 3. Ключевые компоненты и реализация

### 3.1. Паттерн "Универсальный исполнитель"

Модуль спроектирован как универсальная платформа для выполнения **любого** инструмента, который может быть вызван через HTTP POST-запрос с JSON-телом и возвращает JSON-ответ. Это обеспечивает невероятную гибкость.

### 3.2. Строгий API-контракт

Сервис предоставляет четкий и стандартизированный HTTP API:

*   `GET /`: Эндпоинт для проверки работоспособности (Health Check).
*   `POST /tools/{tool_name}`: Универсальный эндпоинт для вызова любого инструмента по его имени.

Ключевую роль в контракте играет **Pydantic**. Для каждого инструмента определяется Pydantic-модель, описывающая его входные параметры. Это гарантирует, что ни один инструмент не будет вызван с некорректными данными — FastAPI отклонит невалидные запросы на уровне веб-сервера.

### 3.3. Безопасное хранилище секретов

Логика управления API-ключами и другими секретами **полностью изолирована** внутри этого микросервиса.

**Пример: ключ для Tavily Web Search**
1.  При старте сервера вызывается функция `load_tavily_key()`.
2.  Она читает API-ключ из файла `env/tavily.env`.
3.  Ключ устанавливается как переменная окружения `TAVILY_API_KEY`, доступная **только** внутри процесса `mcp_server`.

Основное приложение (`react_driver.py`) никогда не видит сам ключ. Оно лишь отправляет запрос на эндпоинт `/tools/web_search`. Это предотвращает утечку ключа в логи, в сетевой трафик между `react_driver` и LLM или в контекст других модулей.

### 3.4. Изоляция зависимостей

Сервис импортирует только те библиотеки, которые необходимы для работы его инструментов. Это предотвращает "раздувание" зависимостей основного приложения и возможные конфликты версий.

## 4. Практические руководства

### 4.1. Конфигурация и запуск

**Конфигурация ключей:**
1.  Создайте директорию `env/` в корне проекта.
2.  Для каждого инструмента, требующего ключ, создайте соответствующий файл (например, `tavily.env`).
3.  Поместите в этот файл API-ключ.

**Запуск сервера:**
Выполните команду в терминале из корневой директории проекта:
```bash
python mcp_server.py
```
Сервер будет запущен и доступен по адресу `http://localhost:8002`.

### 4.2. Пример вызова через `curl`

Вы можете легко протестировать любой инструмент напрямую:
```bash
curl -X POST http://localhost:8002/tools/web_search \
-H "Content-Type: application/json" \
-d '{
  "query": "What are the latest advancements in AI?",
  "max_results": 3
}'
```

### 4.3. Руководство: добавление нового инструмента

Это ключевое преимущество `mcp_server` — простота расширения. Давайте добавим новый инструмент "Агент-Эксперт", который вызывает другого AI-агента.

**Шаг 1: Создайте логику инструмента**

Создайте новый файл `tools/expert_agent.py` с логикой вашего инструмента.

```python
# tools/expert_agent.py
import httpx

# Адрес может указывать на другой эндпоинт этого же прокси
EXPERT_AGENT_ENDPOINT = "http://localhost:8001/v1/react/sessions"

async def get_expert_advice(query: str, domain: str) -> str:
    """Вызывает другого ReAct-агента для получения совета."""
    payload = {
        "user_query": query,
        "model_alias": f"expert_{domain}_model",
        "reasoning_mode": "specialized_react_pattern",
    }
    async with httpx.AsyncClient() as client:
        response = await client.post(EXPERT_AGENT_ENDPOINT, json=payload, timeout=300.0)
        response.raise_for_status()
        return response.json().get("answer", "No expert advice available.")
```

**Шаг 2: Опишите инструмент для LLM**

Добавьте его описание в `tools/available_tools.py`, чтобы основной агент (`react_driver`) знал о его существовании и мог правильно его использовать.

**Шаг 3: Зарегистрируйте эндпоинт в `mcp_server.py`**

Отредактируйте `mcp_server.py`, добавив Pydantic-модель для валидации запроса и сам эндпоинт.

```python
# --- В файле mcp_server.py ---
# ... другие импорты ...
from tools.expert_agent import get_expert_advice # 1. Импортируем нашу логику
from pydantic import BaseModel

# ... существующие Pydantic-модели ...

# 2. Добавляем Pydantic-модель для нового инструмента
class ExpertAgentRequest(BaseModel):
    query: str
    domain: str

# ... существующие эндпоинты ...

# 3. Добавляем новый асинхронный эндпоинт
@app.post("/tools/expert_advice", summary="Получить экспертный совет")
async def run_expert_agent(request: ExpertAgentRequest):
    """
    Вызывает специализированного агента-эксперта для получения консультации.
    """
    try:
        advice = await get_expert_advice(query=request.query, domain=request.domain)
        return {"advice": advice}
    except Exception as e:
        # Логирование ошибки здесь было бы хорошей практикой
        raise HTTPException(status_code=500, detail=str(e))
```

**Готово!** Теперь основной LLM-агент может вызывать `expert_advice` как один из своих инструментов, а `mcp_server` надежно и безопасно оркестрирует этот вызов.

## 5. Архитектурная и бизнес-ценность

*   **Безопасность**: Изоляция API-ключей и секретов в отдельном сервисе кардинально снижает поверхность атаки.
*   **Расширяемость**: Добавление новых инструментов не требует изменения ядра системы, что ускоряет разработку и развертывание.
*   **Масштабируемость**: Сервер инструментов может быть масштабирован независимо от основного приложения.
*   **Простота и чистота кода**: Основной логический модуль (`react_driver`) оперирует простыми и унифицированными HTTP-вызовами, что делает его код чище и проще в поддержке.

В сущности, `mcp_server.py` — это ключевой компонент для построения сложной, модульной, масштабируемой и безопасной AI-системы.