# Техническая Документация: Модуль models.py

## 1. Краткое Резюме

`models.py` — это центральный модуль, определяющий схемы данных (data schemas) для всего приложения с использованием библиотеки Pydantic. Он функционирует как строго типизированный "API-контракт", обеспечивая валидацию, самодокументируемость и надежность всех данных, циркулирующих в системе. Основная роль модуля — описание структур, совместимых со стандартом OpenAI API, что делает шлюз прозрачным и легко интегрируемым для существующих клиентов.

## 2. Архитектурная Роль и Решаемая Проблема

В любом API-ориентированном приложении необходим надежный способ валидации форматов входящих запросов и исходящих ответов. Без такого механизма приложение уязвимо к некорректным данным, что приводит к ошибкам времени выполнения, усложняет отладку и делает API-контракт неявным и хрупким.

`models.py` решает эту проблему, используя Pydantic для создания единого источника правды (Single Source of Truth) для всех моделей данных. Это позволяет:
*   Автоматически валидировать все входящие запросы, отклоняя некорректные на самом "входе" в систему.
*   Гарантировать, что ответы, генерируемые приложением, всегда соответствуют заранее определенной структуре.
*   Предоставлять четкий, машиночитаемый контракт, который используется фреймворком FastAPI для автоматической генерации интерактивной документации.

## 3. Ключевые Модели и Архитектурные Решения

### 3.1. Соответствие Стандарту OpenAI (Основной Принцип)

Подавляющее большинство моделей в этом файле (`ChatCompletionRequest`, `EmbeddingResponse` и др.) целенаправленно и точно дублируют структуру официального API OpenAI.

**Ценность:** Этот подход превращает шлюз в "drop-in" замену для стандартного клиента OpenAI. Любое существующее приложение может быть перенаправлено на данный сервис, просто изменив базовый URL, без необходимости переписывать код, работающий с API.

### 3.2. Поддержка Различных Модальностей

Модели сгруппированы по типам задач, которые они обслуживают:

*   **Chat Completions (Текстовая генерация):**
    *   `ChatCompletionRequest`: Определяет структуру входящего запроса, включая сообщения, параметры генерации и инструменты (tools).
    *   `ChatCompletionResponse`: Стандартный ответ для синхронных запросов.
    *   `ChatCompletionChunk`: Специализированная модель для потоковой передачи (streaming), описывающая отдельный "кусочек" ответа.
*   **Embeddings (Векторные представления):**
    *   `EmbeddingRequest`: Модель для запроса эмбеддингов для строки или списка строк.
    *   `EmbeddingResponse`: Стандартизированный ответ, содержащий векторные представления.
*   **Audio (Речь и Транскрипция):**
    *   `TranscriptionModel` / `TranscriptionResponse`: Модели для задач преобразования речи в текст (STT).
    *   `SpeechCreationRequest`: Модель для задач преобразования текста в речь (TTS). Эта модель была обновлена для полного соответствия последним версиям OpenAI TTS API, включая такие поля, как `voice`, `response_format` и `speed`.

### 3.3. Проприетарная Модель для AI-Агента (ReactRequest)

В отличие от остальных, модель `ReactRequest` не соответствует никакому внешнему стандарту. Она определяет высокоуровневый, внутренний API-контракт для запуска уникальной логики приложения — ReAct-агента.

**Архитектурный нюанс:** Эта модель является точкой входа для наиболее сложной и уникальной функциональности сервиса. Она агрегирует параметры для управления сессиями (`session_id`), поведением агента (`reasoning_mode`), а также позволяет клиенту передавать специфические инструкции и "манифесты" (`client_system_instruction`, `client_manifests`).

## 4. Примеры Использования API

Этот раздел демонстрирует, как Pydantic-модели из этого модуля соответствуют реальным HTTP-запросам к API шлюза.

### 4.1. Запрос на Chat Completion (стандартный)

Этот пример показывает стандартный, не-потоковый запрос к чат-модели. Он использует модель `ChatCompletionRequest`.

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
  "model": "gpt-4-turbo",
  "messages": [
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ],
  "max_tokens": 50,
  "stream": false
}'
```
*   `model`: Указывает псевдоним (`model_alias`) из `proxy_config.yaml`.
*   `stream: false`: Гарантирует, что сервер вернет полный JSON-ответ (`ChatCompletionResponse`) после завершения генерации.

### 4.2. Запрос на Chat Completion (потоковый)

Для интерактивных приложений используется тот же эндпоинт, но с флагом `stream: true`.

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
  "model": "gpt-4-turbo",
  "messages": [
    {
      "role": "user",
      "content": "Write a short story about a robot who discovers music."
    }
  ],
  "stream": true
}'
```
*   `stream: true`: Указывает серверу, что ответ нужно передавать по частям в формате Server-Sent Events (SSE). Каждая часть будет соответствовать модели `ChatCompletionChunk`.

### 4.3. Запрос на Embeddings

Этот пример показывает, как получить векторные представления (эмбеддинги) для текста, используя модель `EmbeddingRequest`.

```bash
curl -X POST http://localhost:8000/v1/embeddings \
-H "Content-Type: application/json" \
-d '{
  "model": "text-embedding-model",
  "input": "Universal AI Gateway provides reliable and scalable access to AI models."
}'
```
Сервер вернет ответ, соответствующий модели `EmbeddingResponse`, со списком векторов.

### 4.4. Запрос на Text-to-Speech (TTS)

Этот пример демонстрирует генерацию речи из текста с помощью модели `SpeechCreationRequest`.

```bash
curl -X POST http://localhost:8000/v1/audio/speech \
-H "Content-Type: application/json" \
-d '{
  "model": "tts-model-alias",
  "input": "Привет, мир! Это универсальный AI шлюз.",
  "voice": "alloy",
  "speed": 1.1
}' \
--output speech.mp3
```
*   `--output speech.mp3`: Флаг `curl` для сохранения потокового аудио-ответа в файл.
*   `voice`, `speed`: Необязательные параметры, которые прокси передаст целевому TTS-провайдеру.

### 4.5. Запрос на запуск ReAct-сессии (Обогащение)

Это самый мощный эндпоинт, использующий проприетарную модель `ReactRequest` для запуска движка рассуждений и обогащения.

```bash
curl -X POST http://localhost:8000/v1/react/sessions \
-H "Content-Type: application/json" \
-d '{
  "user_query": "What is the capital of France and what is the weather there right now?",
  "model_alias": "smart_agent",
  "session_id": "user123-abc",
  "client_system_instruction": "Respond as a helpful and witty tour guide."
}'
```
*   `user_query`: Запрос, требующий сложной логики (в данном случае, двух шагов: найти столицу, затем найти погоду).
*   `model_alias`: Должен указывать на модель, для которой в `proxy_config.yaml` настроен `reasoning_mode`.
*   `session_id`: (Опционально) Позволяет отслеживать или возобновлять сессии.

Сервер ответит потоком Server-Sent Events (SSE), в котором будут транслироваться все этапы работы агента (мысли, вызовы инструментов, финальный ответ).

## 5. Архитектурная Ценность и Бизнес-Эффект

*   **Надежность и Стабильность:** Строгая валидация на основе Pydantic-моделей предотвращает целый класс ошибок, связанных с некорректными данными.
*   **Ускорение Разработки:** Автоматическая генерация документации FastAPI и статическая типизация значительно улучшают опыт разработчиков (Developer Experience).
*   **Стратегическая Совместимость:** Следование стандарту OpenAI является ключевым бизнес-решением, делающим продукт легко встраиваемым в существующую экосистему AI-инструментов.
*   **Четкое Определение Контрактов:** Модуль служит явным и однозначным "договором" о том, в каком виде данные должны поступать в систему и покидать ее.