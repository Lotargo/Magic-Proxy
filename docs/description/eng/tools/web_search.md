# Technical Documentation: The `tools/web_search.py` Tool

## 1. Overview and Architectural Role
`tools/web_search.py` is a specialized tool module that provides the AI agent with the ability to perform internet search queries. It encapsulates all the logic for interacting with the external **Tavily AI** search API, providing a single, simple `search` function for use within `mcp_server.py`.

This tool acts as a **"sensory organ"** for the AI agent, allowing it to go beyond its internal knowledge and access up-to-date, factual information from the real world. This is critically important for solving tasks that require:
*   Real-time data (news, exchange rates, weather).
*   Fact verification (checking claims, finding sources).
*   Information beyond the model's knowledge cutoff (recent events, specific products).

The module is designed to work exclusively in conjunction with `mcp_server.py`, which acts as a secure gateway for it.

## 2. Implementation

### 2.1. Dependency: `tavily-python`
The tool uses the official `tavily-python` library to interact with the Tavily API. This dependency must be installed in the environment where `mcp_server.py` is run.
```bash
pip install tavily-python
```

### 2.2. API Key Management (Security)
The module **does not contain the API key in plain text**. Instead, on its first import, it attempts to read the key from the `TAVILY_API_KEY` environment variable.

The task of setting this environment variable is handled by `mcp_server.py`. On startup, it reads the key from the `env/tavily.env` file and places it in `os.environ`. This way, `web_search.py` receives its key in a secure and isolated manner.

If the environment variable is not found, the `tavily_client` is not created, and the `search` function will return an error, preventing the entire service from crashing.

### 2.3. Main Function: `search()`
```python
def search(query: str, max_results: int = 5) -> dict:
    # ...
```
This is the module's only public function.
*   **Parameters**:
    *   `query: str`: The text search query, which is typically generated by the LLM.
    *   `max_results: int` (defaults to 5): Controls the number of results returned.
*   **Advanced Search**: The function explicitly uses the `search_depth="advanced"` option in the Tavily API. This forces Tavily not just to search, but also to try to synthesize and rank the most relevant results, which improves the quality of the data the LLM receives.
*   **Response Format**: The function always returns a dictionary for unified processing.
    *   **On success**: `{"result": [...]}`
    *   **On error**: `{"error": "..."}`

## 3. Setup and Usage

### 3.1. API Key Setup
1.  Create an `env/` directory in the project root (if it doesn't exist).
2.  Inside, create a file named `tavily.env`.
3.  Place your API key from the Tavily service in this file.

### 3.2. Integration with `mcp_server.py`
The tool must be called via an endpoint defined in `mcp_server.py`.

**Snippet from `mcp_server.py`:**
```python
# 1. Import the function
from tools.web_search import search as web_search_tool

# 2. Pydantic model for request validation
class WebSearchRequest(BaseModel):
    query: str
    max_results: int = 5

# 3. FastAPI endpoint
@app.post("/tools/web_search")
def run_web_search(request: WebSearchRequest):
    try:
        # 4. Call the function from this module
        return web_search_tool(query=request.query, max_results=request.max_results)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### 3.3. Description for the LLM (`available_tools.py`)
For the AI agent to be able to use this tool, it must be described in the `tools/available_tools.py` file. This description serves as an "instruction manual" for the model. (See the documentation for `available_tools.py` for details).